{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix\n"
      ],
      "metadata": {
        "id": "jzBuuaRXpRor"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "train_data = pd.read_csv('/content/train.csv')\n",
        "test_data = pd.read_csv('/content/test.csv')\n",
        "\n",
        "# Simple preprocessing: fill NA values\n",
        "train_data.fillna('', inplace=True)\n",
        "test_data.fillna('', inplace=True)\n",
        "\n",
        "# Combine text data for tokenization\n",
        "combined_text = train_data['text'].tolist() + test_data['text'].tolist()\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(combined_text)\n",
        "\n",
        "# Convert text to sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_data['text'])\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data['text'])\n",
        "\n",
        "# Padding\n",
        "max_length = 200\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post')\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post')\n"
      ],
      "metadata": {
        "id": "5ZD3aGkBpldE"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "train_data = pd.read_csv('/content/train.csv')\n",
        "test_data = pd.read_csv('/content/test.csv')\n",
        "\n",
        "# Preprocess text data\n",
        "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(train_data['text'])\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_data['text'])\n",
        "train_padded = pad_sequences(train_sequences, maxlen=50, padding='post', truncating='post')\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data['text'])\n",
        "test_padded = pad_sequences(test_sequences, maxlen=50, padding='post', truncating='post')\n"
      ],
      "metadata": {
        "id": "BEQbObvNup4P"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN Model\n",
        "model = Sequential([\n",
        "    Embedding(10000, 32, input_length=50),\n",
        "    SimpleRNN(64, return_sequences=False),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "LLpqlmbSu3vv"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_padded, train_data['target'], epochs=5, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcxQtNoLu8Zl",
        "outputId": "f80e7d3d-0e1f-44ee-9109-b0a0f8d24f35"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "191/191 [==============================] - 5s 20ms/step - loss: 0.6815 - accuracy: 0.5826 - val_loss: 0.6949 - val_accuracy: 0.5345\n",
            "Epoch 2/5\n",
            "191/191 [==============================] - 5s 28ms/step - loss: 0.6829 - accuracy: 0.5760 - val_loss: 0.6916 - val_accuracy: 0.5345\n",
            "Epoch 3/5\n",
            "191/191 [==============================] - 4s 18ms/step - loss: 0.6609 - accuracy: 0.6215 - val_loss: 0.6714 - val_accuracy: 0.6461\n",
            "Epoch 4/5\n",
            "191/191 [==============================] - 4s 19ms/step - loss: 0.5625 - accuracy: 0.7343 - val_loss: 0.6190 - val_accuracy: 0.6533\n",
            "Epoch 5/5\n",
            "191/191 [==============================] - 4s 21ms/step - loss: 0.4970 - accuracy: 0.7834 - val_loss: 0.6372 - val_accuracy: 0.6829\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78878aa263e0>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming test_padded contains your preprocessed test data and test_data['target'] are the true labels\n",
        "test_loss, test_accuracy = model.evaluate(test_padded, test_data['target'])\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvD5r8HGxIqN",
        "outputId": "798e0379-ba15-4110-dd77-51fb8daf4d9b"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "238/238 [==============================] - 1s 5ms/step - loss: 0.4658 - accuracy: 0.8044\n",
            "Test Accuracy: 0.8044134974479675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting on the test data\n",
        "test_predictions = model.predict(test_padded)\n",
        "test_predictions = [1 if prob > 0.5 else 0 for prob in test_predictions]\n",
        "\n",
        "# Assuming your test data has a 'target' column with true labels\n",
        "true_labels = test_data['target']\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = accuracy_score(true_labels, test_predictions)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Other metrics\n",
        "f1 = f1_score(true_labels, test_predictions)\n",
        "recall = recall_score(true_labels, test_predictions)\n",
        "precision = precision_score(true_labels, test_predictions)\n",
        "conf_matrix = confusion_matrix(true_labels, test_predictions)\n",
        "\n",
        "# Print the other metrics\n",
        "print(f'F1 Score: {f1}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Confusion Matrix:\\n{conf_matrix}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVkvLoymzMBo",
        "outputId": "61db63d0-44ba-4265-f365-06b3e8925848"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "238/238 [==============================] - 2s 6ms/step\n",
            "Accuracy: 0.8044135032181794\n",
            "F1 Score: 0.7434085817680509\n",
            "Recall: 0.6594313665545705\n",
            "Precision: 0.8518957345971564\n",
            "Confusion Matrix:\n",
            "[[3967  375]\n",
            " [1114 2157]]\n"
          ]
        }
      ]
    }
  ]
}